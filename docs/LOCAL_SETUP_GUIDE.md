# Best Trikotazh Data - Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°

## ğŸ“‹ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

**Best Trikotazh Data** - ÑÑ‚Ğ¾ ETL Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ñ‚Ñ€Ğ¸ĞºĞ¾Ñ‚Ğ°Ğ¶Ğµ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑĞ¾Ğ² Ğ¸ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼.

### Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°:
- **Ğ¡Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** Ñ Wildberries, Ozon, 1C Ñ‡ĞµÑ€ĞµĞ· API
- **ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ°** Ñ‡ĞµÑ€ĞµĞ· Apache Kafka
- **ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°** Ğ² ClickHouse Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ dbt
- **ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ** Ñ‡ĞµÑ€ĞµĞ· Apache Airflow (Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ² 01:00)
- **ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³** Prometheus + Grafana
- **Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ** FastAPI Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ

### Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚ĞµĞº:
- **Kafka KRaft 3.7.1** - Ğ±Ñ€Ğ¾ĞºĞµÑ€ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
- **Python 3.9+** - producers/consumers
- **ClickHouse** - Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ‘Ğ”
- **Airflow** - Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡
- **dbt** - Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- **FastAPI** - Ğ²ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ
- **Prometheus/Grafana** - Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

---

## ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°

### Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ

Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°Ñ ĞµÑÑ‚ÑŒ Ubuntu ÑĞµÑ€Ğ²ĞµÑ€:
```bash
# ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹
git clone https://github.com/aiarsenov/best-trikotazh-data.git
cd best-trikotazh-data

# Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ñ‰Ğ¸Ğº
sudo bash provision/kafka-install.sh

# Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚:
# - Apache Kafka KRaft 3.7.1
# - 5 Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# - systemd ÑĞµÑ€Ğ²Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
# - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ firewall
```

### Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ° macOS/Linux

#### Ğ¨Ğ°Ğ³ 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
```bash
# ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚
git clone https://github.com/aiarsenov/best-trikotazh-data.git
cd best-trikotazh-data

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Python Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
python3 -m venv venv
source venv/bin/activate

# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
pip install -r requirements.txt
```

#### Ğ¨Ğ°Ğ³ 2: Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Docker Ğ´Ğ»Ñ Kafka
```bash
# Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°Ñ Docker Desktop
docker run -d \
  --name kafka \
  -p 9092:9092 \
  -p 19092:19092 \
  -e KAFKA_NODE_ID=1 \
  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT \
  -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \
  confluentinc/cp-kafka:7.4.0

# Ğ–Ğ´Ñ‘Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
sleep 30

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¸
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic wb-keywords --partitions 3 --replication-factor 1

docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic wb-campaigns --partitions 3 --replication-factor 1

docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic ozon-products --partitions 3 --replication-factor 1

docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic onec-entities --partitions 3 --replication-factor 1

docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic etl-logs --partitions 1 --replication-factor 1
```

#### Ğ¨Ğ°Ğ³ 3: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¸
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
echo "test message" | docker exec -i kafka kafka-console-producer --bootstrap-server localhost:9092 --topic wb-keywords

# Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic wb-keywords --from-begin --timeout-ms 5000
```

#### Ğ¨Ğ°Ğ³ 4: Python ĞºĞ»Ğ¸ĞµĞ½Ñ‚
```bash
# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Kafka
pip install kafka-python pandas requests clickhouse-connector
# Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Managed ClickHouse Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ clickhouse-driver (Ğ¿Ğ¾Ñ€Ñ‚ 9440):
pip install clickhouse-driver

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» test_kafka.py
cat > test_kafka.py << 'EOF'
from kafka import KafkaProducer, KafkaConsumer
import json
import time

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
KAFKA_SERVER = 'localhost:9092'

# Producer
producer = KafkaProducer(
    bootstrap_servers=[KAFKA_SERVER],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
producer.send('wb-keywords', value={
    'keyword': 'Ñ„ÑƒÑ‚Ğ±Ğ¾Ğ»ĞºĞ° Ğ¼ÑƒĞ¶ÑĞºĞ°Ñ',
    'position': 1,
    'timestamp': '2025-01-01T00:00:00Z',
    'source': 'test'
})

producer.flush()
print("âœ… Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾!")

# Consumer
consumer = KafkaConsumer(
    'wb-keywords',
    bootstrap_servers=[KAFKA_SERVER],
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest'
)

# Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
print("ğŸ“– Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹...")
for message in consumer:
    print(f"ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {message.value}")
    break

consumer.close()
producer.close()
print("âœ… Ğ¢ĞµÑÑ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½!")
EOF

# Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ñ‚ĞµÑÑ‚
python test_kafka.py
```

---

## ğŸ—ï¸ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° (docker-compose)

Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» `docker-compose.yml`:

```yaml
version: '3.8'

services:
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka-local
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:19092'
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - kafka-data:/var/lib/kafka/data

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: ""
    depends_on:
      - kafka

  # Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ:
  # clickhouse:
  #   image: clickhouse/clickhouse-server:latest
  #   ports:
  #     - "8123:8123"
  #     - "9000:9000"

volumes:
  kafka-data:
```

### Ğ—Ğ°Ğ¿ÑƒÑĞº Ñ docker-compose:
```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ docker-compose.yml Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ
docker-compose up -d

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¸
docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 \
  --create --topic wb-keywords --partitions 3 --replication-factor 1

docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 \
  --create --topic wb-campaigns --partitions 3 --replication-factor 1

docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 \
  --create --topic ozon-products --partitions 3 --replication-factor 1

docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 \
  --create --topic onec-entities --partitions 3 --replication-factor 1

docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 \
  --create --topic etl-logs --partitions 1 --replication-factor 1

# ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ Kafka UI: http://localhost:8080
```

---

## ğŸ› ï¸ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¾Ğ¹

### Docker ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:
```bash
# ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ²
docker exec kafka-local kafka-topics --bootstrap-server localhost:9092 --list

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
echo '{"keyword": "Ğ´Ğ¶Ğ¸Ğ½ÑÑ‹", "category": "Ğ¾Ğ´ĞµĞ¶Ğ´Ğ°"}' | docker exec -i kafka-local kafka-console-producer --bootstrap-server localhost:9092 --topic wb-keywords

# Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
docker exec kafka-local kafka-console-consumer --bootstrap-server localhost:9092 --topic wb-keywords --from-beginning --timeout-ms 10000

# ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²
docker-compose down

# ĞŸĞµÑ€ĞµÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ÑƒĞ»Ñ
docker-compose down -v
docker-compose up -d
```

### Python Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ:
```python
# ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Kafka
from kafka import KafkaProducer
import json

# Ğ”Ğ»Ñ Docker/Kafka UI
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°Ñ…
product_data = {
    'product_id': '12345',
    'name': 'Ğ¤ÑƒÑ‚Ğ±Ğ¾Ğ»ĞºĞ° Ñ Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ¾Ğ¼',
    'price': 599,
    'category': 'Ñ‚Ñ€Ğ¸ĞºĞ¾Ñ‚Ğ°Ğ¶',
    'source': 'wb',
    'timestamp': '2025-01-02T10:30:00Z'
}

producer.send('wb-keywords', value=product_data)
producer.flush()
```

---

## ğŸ”§ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Producers Ğ¸ Consumers

### Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Producer:
```python
# wb_producer.py
import json
import requests
from kafka import KafkaProducer
import time

class WBProducer:
    def __init__(self, kafka_server='localhost:9092'):
        self.producer = KafkaProducer(
            bootstrap_servers=[kafka_server],
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
    
    def fetch_keywords(self, api_token):
        # Ğ—Ğ´ĞµÑÑŒ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Wildberries API
        headers = {
            'Authorization': f'Bearer {api_token}',
            'Content-Type': 'application/json'
        }
        
        response = requests.get(
            'https://suppliers-api.wildberries.ru/api/v1/keywords',
            headers=headers
        )
        
        for keyword_data in response.json()['data']:
            self.producer.send('wb-keywords', value=keyword_data)
        
        self.producer.flush()
        print(f"âœ… ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {len(response.json()['data'])} ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²")

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
if __name__ == "__main__":
    producer = WBProducer()
    # Ğ—Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ½Ğ° Ğ²Ğ°Ñˆ Ñ‚Ğ¾ĞºĞµĞ½ API
    producer.fetch_keywords('your_wb_api_token')
```

### Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Consumer:
```python
# etl_consumer.py
from kafka import KafkaConsumer
import json
import logging

class ETLConsumer:
    def __init__(self, kafka_server='localhost:9092'):
        self.consumer = KafkaConsumer(
            'wb-keywords',
            'wb-campaigns',
            'ozon-products',
            bootstrap_servers=[kafka_server],
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            group_id='etl-processors',
            auto_offset_reset='earliest'
        )
    
    def process_messages(self):
        for message in self.consumer:
            topic = message.topic
            data = message.value
            
            print(f"ğŸ“Š ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾ Ğ¸Ğ· {topic}: {data}")
            
            # Ğ—Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² ClickHouse
            if topic == 'wb-keywords':
                self.process_keyword_data(data)
            elif topic == 'wb-campaigns':
                self.process_campaign_data(data)
    
    def process_keyword_data(self, data):
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
        print(f"ğŸ” ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾: {data}")
    
    def process_campaign_data(self, data):
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
        print(f"ğŸ“ˆ ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ: {data}")

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
if __name__ == "__main__":
    consumer = ETLConsumer()
    consumer.process_messages()
```

---

## ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

### Web UI Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ñ‹:
- **Kafka UI**: http://localhost:8080 (ĞµÑĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚Ğµ docker-compose)
- **ClickHouse**: http://localhost:8123 (ĞµÑĞ»Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚Ğµ Ğ² docker-compose)

### ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ:
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ»Ğ¾Ğ³Ğ¾Ğ² Kafka
docker logs kafka-local

# Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ°Ğ¼
docker exec kafka-local kafka-consumer-groups --bootstrap-server localhost:9092 --describe --all-groups

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸ÑĞºĞ°
docker system df
```

---

## ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ

### âœ… ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞµĞ¹Ñ: end-to-end Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

**Ğ¢ĞµÑÑ‚-ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹**: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Kafka â†’ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ² ClickHouse â†’ Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· dbt

1. **ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Kafka:**
```bash
python3 - <<'PY'
from confluent_kafka import Producer
import json

p = Producer({"bootstrap.servers": "89.169.152.54:9092"})
test_data = [
    {"date": "2024-01-01", "campaign_id": 12345, "keyword": "Ñ‚ĞµÑÑ‚", "impressions": 100, "clicks": 15, "cost": 50.5},
    {"date": "2024-01-02", "campaign_id": 12346, "keyword": "Ñ‚ĞµÑÑ‚2", "impressions": 200, "clicks": 25, "cost": 75.0}
]
for msg in test_data:
    p.produce("wb_keywords", json.dumps(msg).encode('utf-8'))
p.flush()
print("âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ² Kafka")
PY
```

2. **Consumer Ğ´Ğ»Ñ ClickHouse:**
```bash
python3 - <<'PY'
from confluent_kafka import Consumer
from clickhouse_driver import Client
import time

# Kafka consumer
c = Consumer({"bootstrap.servers": "89.169.152.54:9092", "group.id": f"test_{int(time.time())}"})
c.subscribe(["wb_keywords"])

# ClickHouse client (Ğ²Ğ°Ğ¶Ğ½Ğ¾: Ğ¿Ğ¾Ñ€Ñ‚ 9440 Ğ´Ğ»Ñ TLS!)
ch = Client(
    host="rc1a-ioasjmp8oohqnaeo.mdb.yandexcloud.net",
    port=9440,  # âœ… ĞĞ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ TLS Ğ¿Ğ¾Ñ€Ñ‚
    user="databaseuser", 
    password="YOUR_PASSWORD",
    database="best-tricotaz-analytics", 
    secure=True
)

# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ (timeout 15 ÑĞµĞº)
deadline = time.time() + 15
count = 0
while time.time() < deadline:
    msg = c.poll(1.0)
    if msg and not msg.error():
        json_data = msg.value().decode('utf-8')
        # âœ… ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ Ğ´Ğ»Ñ String ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
        ch.execute("INSERT INTO wb_keywords_raw (payload) VALUES", [[json_data]])
        count += 1
        print(f"ğŸ’¾ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ {count} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹")

c.close()
print(f"âœ… ĞšĞ¾Ğ½ÑÑŒÑĞ¼ĞµÑ€ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½. Ğ’ÑĞµĞ³Ğ¾: {count} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹")
PY
```

### âœ… Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚ĞµÑÑ‚Ğ°:
- **Raw Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…**: 9 Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² ClickHouse
- **Staging Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…**: 8 Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ (dbt Ğ¾Ñ‚Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ» 1 Ğ½ĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½ÑƒÑ)
- **Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ñ**: date, campaign_id, keyword, impressions, clicks, cost

## ğŸš€ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

ĞŸĞ¾ÑĞ»Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ¹ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸:

1. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Producers** Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:
   - Wildberries API integration
   - Ozon API integration  
   - 1C API integration

2. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Consumers** Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ² Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ:
   - ClickHouse batch loader
   - Error handling Ğ¸ dead letter queues
   - Data validation

3. **Ğ”ĞµĞ±ÑĞ³Ğ³Ğ¸Ğ½Ğ³ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ**:
   - Unit tests Ğ´Ğ»Ñ producers/consumers
   - Integration tests Ñ Kafka
   - Performance testing

4. **ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğº Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ñƒ**:
   - Environment-specific configurations
   - Monitoring Ğ¸ alerting
   - Documentation Ğ¸ runbooks

---

## â“ Ğ§Ğ°ÑÑ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹

**Q: ĞšĞ°Ğº Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Kafka?**
A: Ğ˜Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ² docker-compose.yml Ğ¸ Ğ¿ĞµÑ€ĞµÑĞ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹

**Q: Ğ“Ğ´Ğµ Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Kafka?**
A: Ğ’ Docker volume `kafka-data` (Ğ´Ğ»Ñ macOS: ~/Library/Containers/com.docker.docker/Data/vms/0/data/docker/volumes/)

**Q: ĞšĞ°Ğº Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ API?**
A: ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº API Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑĞ¾Ğ² Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ URL/headers Ğ² producers

**Q: ĞœĞ¾Ğ³Ñƒ Ğ»Ğ¸ Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ±ĞµĞ· Docker?**
A: Ğ”Ğ°, ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Kafka Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ cloud Kafkas (Upstash, Confluent Cloud)

**Q: Ğ“Ğ´Ğµ Ğ²Ğ·ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…?**
A: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ API ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑĞ¾Ğ² Ğ¸Ğ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ mock-Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

---

**ğŸ“ ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ**: Ğ­Ñ‚Ğ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸. Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ñ Kubernetes, Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒÑ.

**ğŸ”— ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ ÑÑÑ‹Ğ»ĞºĞ¸:**
- [ĞĞ¿ache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Kafka Python Client](https://kafka-python.readthedocs.io/)
- [Docker Kafka Setup](https://docs.confluent.io/platform/current/installation/docker/config-reference.html)
